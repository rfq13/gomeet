apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-config
  namespace: gomeet
data:
  prometheus.yml: |
    global:
      scrape_interval: 10s
      evaluation_interval: 10s
      external_labels:
        cluster: 'gomeet-prod'
        replica: 'prometheus-1'
        
    rule_files:
      - "/etc/prometheus/rules/*.yml"
      
    alerting:
      alertmanagers:
        - static_configs:
            - targets:
              - alertmanager:9093
              
    scrape_configs:
      # Prometheus self-monitoring
      - job_name: 'prometheus'
        static_configs:
          - targets: ['localhost:9090']
        scrape_interval: 30s
        
      # Traefik metrics
      - job_name: 'traefik'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - gomeet
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: traefik
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
        scrape_interval: 5s
        metrics_path: /metrics
        
      # API Services metrics
      - job_name: 'api-services'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - gomeet
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_component]
            action: keep
            regex: api
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_label_app]
            target_label: service
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
        scrape_interval: 5s
        
      # LiveKit SFU metrics
      - job_name: 'livekit-sfu'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - gomeet
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: livekit-sfu
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
        scrape_interval: 3s
        
      # PostgreSQL metrics
      - job_name: 'postgresql'
        static_configs:
          - targets: ['postgres-exporter:9187']
        scrape_interval: 10s
        
      # PgBouncer metrics
      - job_name: 'pgbouncer'
        static_configs:
          - targets: ['pgbouncer-exporter:9127']
        scrape_interval: 5s
        
      # Redis metrics
      - job_name: 'redis'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - gomeet
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: redis
          - source_labels: [__meta_kubernetes_pod_label_role]
            target_label: redis_role
        metrics_path: /metrics
        scrape_interval: 5s
        
      # Kubernetes nodes
      - job_name: 'kubernetes-nodes'
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            regex: (.+)
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
        scrape_interval: 30s
        
      # Kubernetes pods
      - job_name: 'kubernetes-pods'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - gomeet
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
            action: keep
            regex: true
          - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
            action: replace
            target_label: __metrics_path__
            regex: (.+)
          - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            target_label: __address__
        scrape_interval: 30s

  alert_rules.yml: |
    groups:
      - name: gomeet-critical
        rules:
          - alert: HighWebSocketConnections
            expr: sum(websocket_connections_active) > 45000
            for: 2m
            labels:
              severity: critical
              service: signaling
            annotations:
              summary: "WebSocket connections approaching limit"
              description: "Active connections: {{ $value }}/50000"
              
          - alert: SFUCPUHigh
            expr: avg(rate(sfu_cpu_usage_percent[5m])) > 80
            for: 3m
            labels:
              severity: warning
              service: livekit
            annotations:
              summary: "SFU cluster CPU usage high"
              description: "Average CPU: {{ $value }}%"
              
          - alert: SFUBandwidthHigh
            expr: sum(rate(sfu_bandwidth_bytes_per_second[5m])) > 500000000000  # 500Gbps
            for: 5m
            labels:
              severity: warning
              service: livekit
            annotations:
              summary: "SFU bandwidth usage high"
              description: "Current bandwidth: {{ $value | humanize1024 }}B/s"
              
          - alert: SFUParticipantsHigh
            expr: sum(livekit_participants_total) > 48000
            for: 2m
            labels:
              severity: warning
              service: livekit
            annotations:
              summary: "SFU participants approaching limit"
              description: "Active participants: {{ $value }}/50000"
              
          - alert: DatabaseConnectionsHigh
            expr: pg_stat_database_numbackends > 4000
            for: 5m
            labels:
              severity: warning
              service: postgresql
            annotations:
              summary: "Database connections high"
              description: "Active connections: {{ $value }}"
              
          - alert: DatabaseQuerySlow
            expr: histogram_quantile(0.95, rate(pg_stat_statements_mean_time_seconds_bucket[5m])) > 0.1
            for: 5m
            labels:
              severity: warning
              service: postgresql
            annotations:
              summary: "Database queries slow"
              description: "95th percentile query time: {{ $value }}s"
              
          - alert: RedisMemoryHigh
            expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 85
            for: 5m
            labels:
              severity: warning
              service: redis
            annotations:
              summary: "Redis memory usage high"
              description: "Memory usage: {{ $value }}%"
              
          - alert: RedisConnectionsHigh
            expr: redis_connected_clients > 40000
            for: 3m
            labels:
              severity: warning
              service: redis
            annotations:
              summary: "Redis connections high"
              description: "Connected clients: {{ $value }}"
              
          - alert: APIHighErrorRate
            expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
            for: 2m
            labels:
              severity: critical
              service: api
            annotations:
              summary: "API error rate high"
              description: "Error rate: {{ $value | humanizePercentage }}"
              
          - alert: APIHighLatency
            expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
            for: 5m
            labels:
              severity: warning
              service: api
            annotations:
              summary: "API latency high"
              description: "95th percentile latency: {{ $value }}s"
              
          - alert: PodCrashLooping
            expr: rate(kube_pod_container_status_restarts_total[15m]) > 0
            for: 5m
            labels:
              severity: critical
              service: kubernetes
            annotations:
              summary: "Pod is crash looping"
              description: "Pod {{ $labels.pod }} in namespace {{ $labels.namespace }} is crash looping"
              
          - alert: NodeMemoryHigh
            expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 90
            for: 5m
            labels:
              severity: warning
              service: node
            annotations:
              summary: "Node memory usage high"
              description: "Memory usage on {{ $labels.instance }}: {{ $value }}%"
              
          - alert: NodeCPUHigh
            expr: 100 - (avg by(instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
            for: 5m
            labels:
              severity: warning
              service: node
            annotations:
              summary: "Node CPU usage high"
              description: "CPU usage on {{ $labels.instance }}: {{ $value }}%"
              
          - alert: MeetingParticipantsHigh
            expr: sum(gomeet_meeting_participants_active) > 450
            for: 2m
            labels:
              severity: warning
              service: meeting
            annotations:
              summary: "Meeting participants approaching limit"
              description: "Active participants: {{ $value }}/500"
              
          - alert: MeetingLatencyHigh
            expr: histogram_quantile(0.95, rate(gomeet_webrtc_rtt_seconds_bucket[5m])) > 0.2
            for: 3m
            labels:
              severity: warning
              service: webrtc
            annotations:
              summary: "WebRTC latency high"
              description: "95th percentile RTT: {{ $value }}s"
              
          - alert: PacketLossHigh
            expr: rate(gomeet_webrtc_packets_lost_total[5m]) / rate(gomeet_webrtc_packets_total[5m]) > 0.02
            for: 3m
            labels:
              severity: warning
              service: webrtc
            annotations:
              summary: "WebRTC packet loss high"
              description: "Packet loss rate: {{ $value | humanizePercentage }}"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: prometheus
  namespace: gomeet
  labels:
    app: prometheus
    component: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: prometheus
  template:
    metadata:
      labels:
        app: prometheus
        component: monitoring
    spec:
      serviceAccountName: prometheus
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - prometheus
                topologyKey: kubernetes.io/hostname
      containers:
        - name: prometheus
          image: prom/prometheus:v2.40.0
          args:
            - "--config.file=/etc/prometheus/prometheus.yml"
            - "--storage.tsdb.path=/prometheus/"
            - "--web.console.libraries=/etc/prometheus/console_libraries"
            - "--web.console.templates=/etc/prometheus/consoles"
            - "--storage.tsdb.retention.time=90d"
            - "--storage.tsdb.retention.size=200GB"
            - "--web.enable-lifecycle"
            - "--web.enable-admin-api"
            - "--query.max-concurrency=50"
            - "--query.timeout=5m"
          ports:
            - containerPort: 9090
              name: web
          resources:
            requests:
              cpu: 8000m
              memory: 16Gi
            limits:
              cpu: 16000m
              memory: 32Gi
          volumeMounts:
            - name: config
              mountPath: /etc/prometheus
            - name: storage
              mountPath: /prometheus
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: web
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /-/ready
              port: web
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: config
          configMap:
            name: prometheus-config
        - name: storage
          persistentVolumeClaim:
            claimName: prometheus-storage
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: prometheus
  namespace: gomeet
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: prometheus
rules:
  - apiGroups: [""]
    resources: ["nodes", "nodes/metrics", "services", "endpoints", "pods"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["get"]
  - apiGroups: ["networking.k8s.io"]
    resources: ["ingresses"]
    verbs: ["get", "list", "watch"]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: prometheus
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: prometheus
subjects:
  - kind: ServiceAccount
    name: prometheus
    namespace: gomeet
---
apiVersion: v1
kind: Service
metadata:
  name: prometheus
  namespace: gomeet
  labels:
    app: prometheus
    component: monitoring
spec:
  type: ClusterIP
  ports:
    - port: 9090
      targetPort: 9090
      name: web
  selector:
    app: prometheus
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: prometheus-storage
  namespace: gomeet
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 500Gi
  storageClassName: do-block-storage
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: grafana-config
  namespace: gomeet
data:
  grafana.ini: |
    [server]
    domain = grafana.gomeet.com
    root_url = https://grafana.gomeet.com
    serve_from_sub_path = true

    [database]
    type = postgres
    host = postgres-primary:5432
    name = grafana
    user = grafana
    password = ${GF_DATABASE_PASSWORD}

    [security]
    admin_user = admin
    admin_password = ${GF_SECURITY_ADMIN_PASSWORD}
    secret_key = ${GF_SECURITY_SECRET_KEY}

    [auth.anonymous]
    enabled = false

    [users]
    allow_sign_up = false

    [smtp]
    enabled = true
    host = smtp.gmail.com:587
    user = ${GF_SMTP_USER}
    password = ${GF_SMTP_PASSWORD}
    from_address = noreply@gomeet.com

    [alerting]
    enabled = true
    execute_alerts = true

    [unified_alerting]
    enabled = true

    [metrics]
    enabled = true

    [tracing.jaeger]
    enabled = true

  datasources.yml: |
    apiVersion: 1
    datasources:
      - name: Prometheus
        type: prometheus
        access: proxy
        url: http://prometheus:9090
        isDefault: true
        editable: true
        jsonData:
          timeInterval: "10s"
          queryTimeout: "120s"
          httpMethod: POST
          
      - name: PostgreSQL
        type: postgres
        access: proxy
        url: postgres-primary:5432
        database: gomeet_primary
        user: postgres
        secureJsonData:
          password: ${POSTGRES_PASSWORD}
        jsonData:
          postgresVersion: 1500
          timescaledb: false
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
  namespace: gomeet
  labels:
    app: grafana
    component: monitoring
spec:
  replicas: 3
  selector:
    matchLabels:
      app: grafana
  template:
    metadata:
      labels:
        app: grafana
        component: monitoring
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - grafana
                topologyKey: kubernetes.io/hostname
      containers:
        - name: grafana
          image: grafana/grafana:9.3.0
          env:
            - name: GF_DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gomeet-secrets
                  key: GRAFANA_DB_PASSWORD
            - name: GF_SECURITY_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gomeet-secrets
                  key: GRAFANA_ADMIN_PASSWORD
            - name: GF_SECURITY_SECRET_KEY
              valueFrom:
                secretKeyRef:
                  name: gomeet-secrets
                  key: GRAFANA_SECRET_KEY
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gomeet-secrets
                  key: POSTGRES_PASSWORD
            - name: GF_SMTP_USER
              valueFrom:
                secretKeyRef:
                  name: gomeet-secrets
                  key: SMTP_USER
            - name: GF_SMTP_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: gomeet-secrets
                  key: SMTP_PASSWORD
          ports:
            - containerPort: 3000
              name: web
          resources:
            requests:
              cpu: 2000m
              memory: 4Gi
            limits:
              cpu: 4000m
              memory: 8Gi
          volumeMounts:
            - name: config
              mountPath: /etc/grafana
            - name: storage
              mountPath: /var/lib/grafana
            - name: dashboards
              mountPath: /etc/grafana/provisioning/dashboards
          livenessProbe:
            httpGet:
              path: /api/health
              port: web
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /api/health
              port: web
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: config
          configMap:
            name: grafana-config
        - name: storage
          persistentVolumeClaim:
            claimName: grafana-storage
        - name: dashboards
          configMap:
            name: grafana-dashboards
---
apiVersion: v1
kind: Service
metadata:
  name: grafana
  namespace: gomeet
  labels:
    app: grafana
    component: monitoring
spec:
  type: ClusterIP
  ports:
    - port: 3000
      targetPort: 3000
      name: web
  selector:
    app: grafana
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: grafana-storage
  namespace: gomeet
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
  storageClassName: do-block-storage
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: alertmanager
  namespace: gomeet
  labels:
    app: alertmanager
    component: monitoring
spec:
  replicas: 2
  selector:
    matchLabels:
      app: alertmanager
  template:
    metadata:
      labels:
        app: alertmanager
        component: monitoring
    spec:
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchExpressions:
                    - key: app
                      operator: In
                      values:
                        - alertmanager
                topologyKey: kubernetes.io/hostname
      containers:
        - name: alertmanager
          image: prom/alertmanager:v0.25.0
          args:
            - "--config.file=/etc/alertmanager/alertmanager.yml"
            - "--storage.path=/alertmanager"
            - "--web.external-url=https://alertmanager.gomeet.com"
          ports:
            - containerPort: 9093
              name: web
          resources:
            requests:
              cpu: 1000m
              memory: 2Gi
            limits:
              cpu: 2000m
              memory: 4Gi
          volumeMounts:
            - name: config
              mountPath: /etc/alertmanager
            - name: storage
              mountPath: /alertmanager
          livenessProbe:
            httpGet:
              path: /-/healthy
              port: web
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /-/ready
              port: web
            initialDelaySeconds: 5
            periodSeconds: 5
      volumes:
        - name: config
          configMap:
            name: alertmanager-config
        - name: storage
          persistentVolumeClaim:
            claimName: alertmanager-storage
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: alertmanager-config
  namespace: gomeet
data:
  alertmanager.yml: |
    global:
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_from: 'alerts@gomeet.com'
      smtp_auth_username: '${SMTP_USER}'
      smtp_auth_password: '${SMTP_PASSWORD}'
      
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 1h
      receiver: 'web.hook'
      routes:
      - match:
          severity: critical
        receiver: 'critical-alerts'
      - match:
          severity: warning
        receiver: 'warning-alerts'
        
    receivers:
    - name: 'web.hook'
      webhook_configs:
      - url: 'http://notification-service:8080/webhooks/alerts'
        send_resolved: true
        
    - name: 'critical-alerts'
      email_configs:
      - to: 'oncall@gomeet.com'
        subject: '[CRITICAL] {{ .GroupLabels.alertname }} in {{ .GroupLabels.cluster }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ range .Labels.SortedPairs }}{{ .Name }}={{ .Value }} {{ end }}
          {{ end }}
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts-critical'
        title: 'Critical Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        
    - name: 'warning-alerts'
      email_configs:
      - to: 'devops@gomeet.com'
        subject: '[WARNING] {{ .GroupLabels.alertname }} in {{ .GroupLabels.cluster }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Labels: {{ range .Labels.SortedPairs }}{{ .Name }}={{ .Value }} {{ end }}
          {{ end }}
      slack_configs:
      - api_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts-warning'
        title: 'Warning Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        
    inhibit_rules:
    - source_match:
        severity: 'critical'
      target_match:
        severity: 'warning'
      equal: ['alertname', 'cluster', 'service']
---
apiVersion: v1
kind: Service
metadata:
  name: alertmanager
  namespace: gomeet
  labels:
    app: alertmanager
    component: monitoring
spec:
  type: ClusterIP
  ports:
    - port: 9093
      targetPort: 9093
      name: web
  selector:
    app: alertmanager
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: alertmanager-storage
  namespace: gomeet
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 20Gi
  storageClassName: do-block-storage
